{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f6b8f3587f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "                                                 \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(linewidth = 120)\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## collects in 2 folders \n",
    "\n",
    "## alpha and beta \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def collect_and_save(foldername, count):\n",
    "    \n",
    "    os.mkdir(foldername)\n",
    "    \n",
    "    faces_rect = ()\n",
    "    \n",
    "    def detect_faces(cascade, test_image):\n",
    "        global counter \n",
    "        global faces_rect\n",
    "        gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)   # opencv detects stuff in gray\n",
    "\n",
    "        faces_rect = cascade.detectMultiScale(gray_image)  # classifier \n",
    "\n",
    "        for (x, y, w, h) in faces_rect:\n",
    "            cv2.rectangle(gray_image, (x - 20, y-20), (x+w+ 20, y+h+70), (255, 0, 0), 8)   ## slight padding added to make sure the full face comes in \n",
    "\n",
    "        if faces_rect != ():\n",
    "\n",
    "                fmt_name = foldername + \"/\" + str(faces_rect) +\".png\"\n",
    "\n",
    "                crop_img = gray_image[y:y+h+70, x-20 :x+w +20]     ## added some padding  as + 20 and - 70\n",
    "\n",
    "                cv2.imwrite(fmt_name,crop_img)\n",
    "                \n",
    "               ## crop\n",
    "        return gray_image\n",
    "\n",
    "    def feed(count):    ## q to quit \n",
    "        \n",
    "        print (\" will collect images for face now -- \")\n",
    "        print (\"\")\n",
    "        input(\"press enter to continue --\")\n",
    "        \n",
    "        counter = 0 \n",
    "        global faces_rect\n",
    "        haar_cascade_face = cv2.CascadeClassifier('/home/mayukh09/anaconda3/lib/python3.7/site-packages/cv2/data/haarcascade_frontalcatface.xml')\n",
    "\n",
    "        ## CAMERA CAPTURE FEED \n",
    "        cap = cv2.VideoCapture(0)\n",
    "\n",
    "        while counter < count:                    \n",
    "            # Capture frame-by-frame\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            frame = detect_faces(haar_cascade_face, frame)\n",
    "            \n",
    "            if faces_rect != ():\n",
    "                counter+= 1\n",
    "                print (\"collected \", faces_rect,\".png\")\n",
    "                \n",
    "            cv2.imshow('frame', frame)\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):    ## press q to quit \n",
    "                break\n",
    "\n",
    "        # When done, release the capture\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    feed(count)\n",
    "    \n",
    "    print (\"\")\n",
    "    print (count, \" photos saved in  -- \", foldername)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " will collect images for face now -- \n",
      "\n",
      "press enter to continue --\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayukh09/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:24: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "/home/mayukh09/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:54: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collected  [[194 156 152 152]] .png\n",
      "collected  [[189 148 166 166]] .png\n",
      "collected  [[188 151 163 163]] .png\n",
      "collected  [[193 154 157 157]] .png\n",
      "collected  [[192 151 159 159]] .png\n",
      "collected  [[191 151 155 155]] .png\n",
      "collected  [[193 153 156 156]] .png\n",
      "collected  [[196 154 152 152]] .png\n",
      "collected  [[195 154 152 152]] .png\n",
      "collected  [[192 155 157 157]] .png\n",
      "collected  [[191 157 155 155]] .png\n",
      "collected  [[193 157 152 152]] .png\n",
      "collected  [[192 156 155 155]] .png\n",
      "collected  [[192 152 156 156]] .png\n",
      "collected  [[193 158 150 150]] .png\n",
      "collected  [[199 160 140 140]] .png\n",
      "collected  [[193 155 150 150]] .png\n",
      "collected  [[191 152 156 156]] .png\n",
      "collected  [[196 155 147 147]] .png\n",
      "collected  [[195 155 145 145]] .png\n",
      "collected  [[186 154 155 155]] .png\n",
      "collected  [[188 161 146 146]] .png\n",
      "collected  [[109 140 185 185]] .png\n",
      "collected  [[112 139 171 171]] .png\n",
      "collected  [[121 140 153 153]] .png\n",
      "collected  [[114 134 167 167]] .png\n",
      "collected  [[112 137 172 172]] .png\n",
      "collected  [[117 147 205 205]] .png\n",
      "collected  [[146 141 168 168]] .png\n",
      "collected  [[172 154 140 140]] .png\n",
      "collected  [[165 138 189 189]] .png\n",
      "collected  [[194 149 154 154]] .png\n",
      "collected  [[197 139 166 166]] .png\n",
      "collected  [[215 145 156 156]] .png\n",
      "collected  [[222 146 155 155]] .png\n",
      "collected  [[271 220  54  54]] .png\n",
      "collected  [[242 145 159 159]] .png\n",
      "collected  [[246 152 148 148]] .png\n",
      "collected  [[232 150 149 149]] .png\n",
      "collected  [[220 144 155 155]] .png\n",
      "collected  [[214 152 146 146]] .png\n",
      "collected  [[205 151 145 145]] .png\n",
      "collected  [[198 153 137 137]] .png\n",
      "collected  [[184 140 147 147]] .png\n",
      "collected  [[184 145 144 144]] .png\n",
      "collected  [[184 133 154 154]] .png\n",
      "collected  [[183 140 147 147]] .png\n",
      "collected  [[174 137 164 164]] .png\n",
      "collected  [[170 150 177 177]] .png\n",
      "collected  [[176 145 158 158]] .png\n",
      "\n",
      "50  photos saved in  --  alpha\n",
      " will collect images for face now -- \n",
      "\n",
      "press enter to continue --\n",
      "collected  [[242 173 154 154]] .png\n",
      "collected  [[248 174 149 149]] .png\n",
      "collected  [[240 176 167 167]] .png\n",
      "collected  [[259 196 127 127]] .png\n",
      "collected  [[256 184 130 130]] .png\n",
      "collected  [[257 195 116 116]] .png\n",
      "collected  [[261 189 121 121]] .png\n",
      "collected  [[257 186 125 125]] .png\n",
      "collected  [[253 190 121 121]] .png\n",
      "collected  [[260 198 118 118]] .png\n",
      "collected  [[269 188 113 113]] .png\n",
      "collected  [[267 197 117 117]] .png\n",
      "collected  [[271 175 122 122]] .png\n",
      "collected  [[278 178 113 113]] .png\n",
      "collected  [[268 170 134 134]] .png\n",
      "collected  [[240 141 181 181]] .png\n",
      "collected  [[271 176 132 132]] .png\n",
      "collected  [[270 174 126 126]] .png\n",
      "collected  [[266 164 140 140]] .png\n",
      "collected  [[272 174 126 126]] .png\n",
      "collected  [[253 152 175 175]] .png\n",
      "collected  [[267 166 143 143]] .png\n",
      "collected  [[258 155 160 160]] .png\n",
      "collected  [[268 172 130 130]] .png\n",
      "collected  [[274 174 129 129]] .png\n",
      "collected  [[255 156 168 168]] .png\n",
      "collected  [[270 175 129 129]] .png\n",
      "collected  [[276 186 113 113]] .png\n",
      "collected  [[269 178 124 124]] .png\n",
      "collected  [[252 169 162 162]] .png\n",
      "collected  [[262 172 142 142]] .png\n",
      "collected  [[276 186 106 106]] .png\n",
      "collected  [[245 157 183 183]] .png\n",
      "collected  [[239 129 185 185]] .png\n",
      "collected  [[233 122 210 210]] .png\n",
      "collected  [[252 136 176 176]] .png\n",
      "collected  [[241 131 187 187]] .png\n",
      "collected  [[233 120 196 196]] .png\n",
      "collected  [[250 147 157 157]] .png\n",
      "collected  [[255 155 158 158]] .png\n",
      "collected  [[249 144 178 178]] .png\n",
      "collected  [[252 142 179 179]] .png\n",
      "collected  [[240 136 197 197]] .png\n",
      "collected  [[230 125 220 220]] .png\n",
      "collected  [[242 143 188 188]] .png\n",
      "collected  [[243 142 184 184]] .png\n",
      "collected  [[262 169 134 134]] .png\n",
      "collected  [[221 127 220 220]] .png\n",
      "collected  [[251 155 156 156]] .png\n",
      "collected  [[247 162 162 162]] .png\n",
      "\n",
      "50  photos saved in  --  beta\n"
     ]
    }
   ],
   "source": [
    "collect_and_save(\"alpha\", 50)\n",
    "\n",
    "collect_and_save(\"beta\", 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_processor(): \n",
    "    \n",
    "    os.mkdir(\"numpy\")\n",
    "    \n",
    "    print (\"processing images now ...\")\n",
    "    \n",
    "    def load_images_from_folder(folder):\n",
    "        images = []\n",
    "        for filename in os.listdir(folder):\n",
    "            path = folder +\"/\"+ filename\n",
    "\n",
    "            im = Image.open(path)\n",
    "\n",
    "            im = im.convert('L')\n",
    "            \n",
    "            # grayscale because sneakyboi was born colorblind\n",
    "\n",
    "            images.append(im)\n",
    "        return images\n",
    "\n",
    "\n",
    "    def convert_to_numpy(arr, vector):\n",
    "        np_arr = []\n",
    "        for p in range (len(arr)):\n",
    "            mario =  [np.array(arr[p]), vector]\n",
    "            np_arr.append(mario)\n",
    "        return np_arr\n",
    "\n",
    "    def normalise(arr, width, height):  ## resize and standardise\n",
    "        arr_copy = arr\n",
    "        for p in range (len(arr)):\n",
    "            doofus = arr[p]\n",
    "            doofus = doofus.resize((width, height), Image.ANTIALIAS)\n",
    "            arr_copy[p]= doofus\n",
    "        return arr_copy\n",
    "\n",
    "\n",
    "    def save(arr, name):\n",
    "        fmt_name  = \"numpy/\" + name   # numpy array saver\n",
    "        np.save(fmt_name, arr)\n",
    "\n",
    "        print (\"saved -- \", fmt_name)\n",
    "\n",
    "    def cvt_raw_data():\n",
    "\n",
    "        alpha_arr = load_images_from_folder(\"alpha\")\n",
    "        beta_arr = load_images_from_folder(\"beta\")\n",
    "\n",
    "\n",
    "        alpha_norm = normalise(alpha_arr , 200, 200)\n",
    "        beta_norm = normalise(beta_arr , 200, 200)\n",
    "\n",
    "\n",
    "        alpha_final = convert_to_numpy(alpha_norm, [0])\n",
    "        beta_final = convert_to_numpy(beta_norm, [1])\n",
    "\n",
    "\n",
    "        save(alpha_final, \"alpha_final\")\n",
    "        save(beta_final, \"beta_final\")\n",
    "        \n",
    "    cvt_raw_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing images now ...\n",
      "saved --  numpy/alpha_final\n",
      "saved --  numpy/beta_final\n"
     ]
    }
   ],
   "source": [
    "img_processor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       ...,\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255],\n",
      "       [255, 255, 255, ..., 255, 255, 255]], dtype=uint8)\n",
      " list([0])]\n"
     ]
    }
   ],
   "source": [
    "foo = np.array(np.load(\"numpy/alpha_final.npy\"))   # checking a sample frame \n",
    "\n",
    "print (foo[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalise_data():\n",
    "    \n",
    "    \n",
    "    def preprocess( arr1, arr2 ):\n",
    "\n",
    "        alpha = np.array(np.load(arr1))\n",
    "        beta = np.array(np.load(arr2))\n",
    "\n",
    "        gamma = np.concatenate((alpha, beta), axis = 0)  # concatenates - as the word is sugesting \n",
    "        \n",
    "\n",
    "        np.random.shuffle(gamma)\n",
    "\n",
    "        np.save (\"numpy/binary_shuffled.npy\", gamma)\n",
    "        print (\"final array has been saved as --   binary_shuffled.npy  - in folder -- numpy\" )\n",
    "\n",
    "\n",
    "    preprocess(\"numpy/alpha_final.npy\", \"numpy/beta_final.npy\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final array has been saved as --   binary_shuffled.npy  - in folder -- numpy\n"
     ]
    }
   ],
   "source": [
    "finalise_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################  ALL FINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chug_to_tensor(images,labels):\n",
    "    images = torch.from_numpy(images)\n",
    "    labels = torch.tensor(labels)\n",
    "    images = images.unsqueeze(0)\n",
    "    images = images.unsqueeze(0)\n",
    " \n",
    "    images = images.type(torch.float32)\n",
    "\n",
    "    return (images,labels)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        \n",
    "        # in_channels = 1, out_channels = 10 kernel_size = 5 (kernel is the filter thingy )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(4, 4)   ## changed from (3,3) to (4,4)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(10, 20, 5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2420, 125)       # linear starts \n",
    "        self.fc2 = nn.Linear(125, 80)\n",
    "        self.fc3 = nn.Linear(80, 2)   ## op\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 2420)                   # reshape thingy\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        \n",
    "## DO NOT USE SOFTMAX AND CROSSENTROPY TOGETHER, USE relu FOR CrossEntropyLoss\n",
    "\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "facenet = Net()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss_arr = []\n",
    "epoch_arr = []\n",
    "\n",
    "\n",
    "def train_loop(epochs):\n",
    "    \n",
    "    foo = np.array(np.load(\"numpy/binary_shuffled.npy\"))\n",
    "        \n",
    "    peanut = foo\n",
    "    \n",
    "    \n",
    "    global loss_arr\n",
    "    \n",
    "    global epoch_arr \n",
    "        \n",
    "    \n",
    "    optimizer = optim.Adam(facenet.parameters(), lr = 0.001)\n",
    "    \n",
    "    for m in range (epochs):\n",
    "\n",
    "\n",
    "        epoch_loss = 0\n",
    "\n",
    "        single_batch = next(iter(peanut))\n",
    "\n",
    "        for single_batch in peanut:\n",
    "\n",
    "            image, label = single_batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            image,label = chug_to_tensor(image, label)\n",
    "\n",
    "            pred = facenet(image).squeeze(1)\n",
    "            \n",
    "           \n",
    "\n",
    "            loss = F.cross_entropy(pred,label)    # pain to fix if messed up\n",
    "\n",
    "            loss.backward()   #backprop\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss\n",
    "            \n",
    "            \n",
    "        print ( m + 1, \" epoch    \", \"loss  - \", epoch_loss.item() )\n",
    "        \n",
    "        threshold = torch.tensor([0.1])\n",
    "        \n",
    "        if torch.gt(threshold, epoch_loss):     ## prevent overtraining\n",
    "            \n",
    "            print (\"----\")\n",
    "            print (' overtraining prevented, loss was too low ')\n",
    "            print (\"----\")\n",
    "            break\n",
    "         \n",
    "    \n",
    "        epoch_loss = epoch_loss.item()\n",
    "\n",
    "        loss_arr.append(epoch_loss)\n",
    "        epoch_arr.append(m+1)\n",
    "            \n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    print (\"training  done  \")  \n",
    "\n",
    "\n",
    "def train_main():\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    mario = int(input(\"enter number of epochs > 30 would be enough :  \"))\n",
    "    train_loop(mario)\n",
    "    \n",
    "def show_analysis():\n",
    "    \n",
    "    global loss_arr\n",
    "    global epoch_arr\n",
    "    def show_plot(epoch_arr, loss_arr):\n",
    "        #print (loss_arr)\n",
    "        plt.plot(epoch_arr, loss_arr, linewidth = 1.0 )\n",
    "        plt.ylabel(\" loss \")\n",
    "        \n",
    "        plt.xlabel(\" epochs \")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "    show_plot(epoch_arr, loss_arr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter number of epochs > 30 would be enough :  45\n",
      "1  epoch     loss  -  74.719970703125\n",
      "2  epoch     loss  -  15.201547622680664\n",
      "3  epoch     loss  -  1.5519505739212036\n",
      "4  epoch     loss  -  31.677095413208008\n",
      "5  epoch     loss  -  8.231146812438965\n",
      "6  epoch     loss  -  4.368175983428955\n",
      "7  epoch     loss  -  0.0019258648389950395\n",
      "----\n",
      " overtraining prevented, loss was too low \n",
      "----\n",
      "training  done  \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_main()\n",
    "\n",
    "show_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mayukh09/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face !\n",
      "tensor([[ 3.7057, -1.1877]], grad_fn=<AddmmBackward>)\n",
      "prediction  --------------------------  tensor(0)\n",
      "face !\n",
      "tensor([[ 4.4060, -1.4023]], grad_fn=<AddmmBackward>)\n",
      "prediction  --------------------------  tensor(0)\n",
      "face !\n",
      "tensor([[ 6.2794, -2.5868]], grad_fn=<AddmmBackward>)\n",
      "prediction  --------------------------  tensor(0)\n",
      "face !\n",
      "tensor([[-2.0238,  2.5389]], grad_fn=<AddmmBackward>)\n",
      "prediction  --------------------------  tensor(1)\n",
      "face !\n",
      "tensor([[-0.2313,  1.1889]], grad_fn=<AddmmBackward>)\n",
      "prediction  --------------------------  tensor(1)\n",
      "face !\n",
      "tensor([[-4.5694,  4.6053]], grad_fn=<AddmmBackward>)\n",
      "prediction  --------------------------  tensor(1)\n",
      "face !\n",
      "tensor([[-4.2456,  4.3542]], grad_fn=<AddmmBackward>)\n",
      "prediction  --------------------------  tensor(1)\n",
      "face !\n",
      "tensor([[-3.4678,  3.7440]], grad_fn=<AddmmBackward>)\n",
      "prediction  --------------------------  tensor(1)\n"
     ]
    }
   ],
   "source": [
    "def convert_to_tensor(images):\n",
    "    \n",
    "    images = torch.from_numpy(images)\n",
    "    \n",
    "    images = images.unsqueeze(0)\n",
    "    images = images.unsqueeze(0)\n",
    " \n",
    "    images = images.type(torch.float32)\n",
    "\n",
    "    return (images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "faces_rect = ()\n",
    "def detect_faces(cascade, test_image):\n",
    "\n",
    "    global faces_rect\n",
    "    gray_image = cv2.cvtColor(test_image, cv2.COLOR_BGR2GRAY)   # opencv detects stuff in gray\n",
    "\n",
    "    faces_rect = cascade.detectMultiScale(gray_image)  # classifier \n",
    "   \n",
    "    \n",
    "    \n",
    "    for (x, y, w, h) in faces_rect:\n",
    "        \n",
    "        cv2.rectangle(gray_image, (x - 20, y-20), (x+w+ 20, y+h+70), (255, 0, 0), 8)   \n",
    "        \n",
    "        ## slight padding added to make sure the full face comes in \n",
    "        \n",
    "    if faces_rect != ():\n",
    "            print (\"face !\")\n",
    "            crop_img = gray_image[y:y+h+70, x-20 :x+w +20]\n",
    "            \n",
    "            \n",
    "#             print (crop_img)\n",
    "            \n",
    "            img = Image.fromarray(crop_img)\n",
    "\n",
    "            img = img.resize((200, 200), Image.ANTIALIAS)  # resize\n",
    "    \n",
    "           \n",
    "\n",
    "            im = np.array(img)\n",
    "\n",
    "\n",
    "            im = torch.from_numpy(im)\n",
    "            im = im.unsqueeze(0)\n",
    "            im = im.unsqueeze(0)      # convert to 4d torch tensor\n",
    "\n",
    "            im = im.float()\n",
    "\n",
    "            res = facenet(im)\n",
    "            \n",
    "            print(res)\n",
    "            \n",
    "            prediction = res.argmax()\n",
    "            print (\"prediction  -------------------------- \", prediction)\n",
    "            \n",
    "        \n",
    "           \n",
    "    return gray_image\n",
    "\n",
    "\n",
    "\n",
    "def cam_feed():    ## q to quit \n",
    "    global faces_rect\n",
    "    haar_cascade_face = cv2.CascadeClassifier('/home/mayukh09/anaconda3/lib/python3.7/site-packages/cv2/data/haarcascade_frontalcatface.xml')\n",
    "\n",
    "    ## CAMERA CAPTURE FEED \n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    while(True):                    \n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "\n",
    "        \n",
    "        frame = detect_faces(haar_cascade_face, frame)\n",
    " \n",
    "        \n",
    "        \n",
    "       \n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # When done, release the capture\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    \n",
    "cam_feed()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initially I was showing anant's face to which it showed the prediction as 0 \n",
    "\n",
    "## and then I showed my face to which the prediction came to be 1 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
